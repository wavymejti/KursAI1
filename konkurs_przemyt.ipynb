{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJAQvFeQ970DQsk4iqVJFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wavymejti/KursAI1/blob/main/konkurs_przemyt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YbR6_yeZmBVL"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# W przypadku błędu: 'No module named tensorflow', odkomentuj i uruchom:\n",
        "# !pip install tensorflow opencv-python numpy matplotlib scikit-learn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import cv2 # OpenCV do ładowania obrazów\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import drive # Do montowania Dysku Google"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- USTAWIA GŁÓWNY KATALOG Z DANYMI ---\n",
        "# 1. Montowanie Dysku Google\n",
        "# Po uruchomieniu tego, kliknij w link i zezwól Colab na dostęp do Twojego Dysku.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Ścieżka do folderu z \"czystymi pojazdami\"\n",
        "# Zmień tę ścieżkę na właściwą dla Twojego katalogu na Dysku Google.\n",
        "DATA_DIR = '/content/drive/MyDrive/Twoj_Katalog_Z_Czystymi_Pojazdami/'\n",
        "\n",
        "# Parametry obrazów RTG\n",
        "IMG_HEIGHT = 512  # Ustawienie rozsądnej, mniejszej wysokości dla przyspieszenia\n",
        "IMG_WIDTH = 512   # Ustawienie rozsądnej, mniejszej szerokości\n",
        "# Pamiętaj: Skalowanie do mniejszego rozmiaru może powodować utratę bardzo małych anomalii.\n",
        "# Dla 50MB plików, musisz zredukować rozmiar lub użyć zaawansowanego sprzętu (GPU High-RAM).\n",
        "CHANNELS = 1      # 1 kanał, bo obrazy RTG są zazwyczaj monochromatyczne (grayscale)\n",
        "\n",
        "def load_and_preprocess_data(data_dir, target_size, channels=1):\n",
        "    \"\"\"Ładuje i przetwarza obrazy z folderu.\"\"\"\n",
        "    image_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
        "                   if f.endswith(('.bmp', '.png', '.jpg'))]\n",
        "\n",
        "    data = []\n",
        "    print(f\"Znaleziono {len(image_paths)} plików.\")\n",
        "\n",
        "    for path in image_paths:\n",
        "        # Wczytanie obrazu w skali szarości (cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if channels == 1 else cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is not None:\n",
        "            # Skalowanie obrazu do docelowego rozmiaru\n",
        "            img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "            # Normalizacja do zakresu [0, 1]\n",
        "            img = img.astype('float32') / 255.0\n",
        "            data.append(img)\n",
        "        else:\n",
        "            print(f\"Ostrzeżenie: Nie udało się załadować pliku {path}\")\n",
        "\n",
        "    # Konwersja na tablicę NumPy i dodanie wymiaru kanału/partii (batch)\n",
        "    data = np.array(data)\n",
        "    if channels == 1:\n",
        "        data = np.expand_dims(data, axis=-1)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Ładowanie danych\n",
        "print(\"--- Ładowanie i przetwarzanie danych ---\")\n",
        "X_clean = load_and_preprocess_data(DATA_DIR, (IMG_WIDTH, IMG_HEIGHT), CHANNELS)\n",
        "\n",
        "if len(X_clean) == 0:\n",
        "    print(\"BŁĄD: Nie znaleziono żadnych plików w katalogu. Sprawdź ścieżkę i rozszerzenia.\")\n",
        "    # Zakończenie skryptu, jeśli brak danych\n",
        "    # exit()\n",
        "\n",
        "# Podział na zbiór treningowy i walidacyjny (np. 80% / 20%)\n",
        "X_train, X_val = train_test_split(X_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Zbiór treningowy: {X_train.shape[0]} obrazów\")\n",
        "print(f\"Zbiór walidacyjny: {X_val.shape[0]} obrazów\")\n",
        "\n",
        "\n",
        "# --- BUDOWA MODELU KONWOLUCYJNEGO AUTOENKODERA (CAE) - Architektura U-Net podobna ---\n",
        "\n",
        "def build_cae(input_shape):\n",
        "    \"\"\"Definiuje model Konwolucyjnego Autoenkodera z architekturą U-Net.\"\"\"\n",
        "\n",
        "    input_img = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # === ENKODER (Encoder) ===\n",
        "    # Kompresja danych\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x) # 256x256\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x) # 128x128\n",
        "\n",
        "    # Opcjonalne: Użycie dropoutu do zapobiegania nadmiernemu dopasowaniu\n",
        "    # x = layers.Dropout(0.2)(encoded)\n",
        "\n",
        "    # === DEKODER (Decoder) ===\n",
        "    # Rekonstrukcja danych\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x) # 256x256\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x) # 512x512\n",
        "\n",
        "    # Ostatnia warstwa - musi mieć taką samą liczbę kanałów jak wejście (np. 1 dla grayscale)\n",
        "    decoded = layers.Conv2D(CHANNELS, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Utworzenie modelu\n",
        "    autoencoder = models.Model(input_img, decoded)\n",
        "\n",
        "    # Kompilacja modelu: Mean Squared Error (MSE) jest standardową funkcją straty dla autoenkoderów\n",
        "    # MSE jest bezpośrednim pomiarem błędu rekonstrukcji\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# Budowa modelu\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
        "cae_model = build_cae(input_shape)\n",
        "\n",
        "print(\"\\n--- Struktura Modelu Autoenkodera ---\")\n",
        "cae_model.summary()"
      ],
      "metadata": {
        "id": "cTDVqdOUmf0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TRENOWANIE MODELU ---\n",
        "# Trening: Na wejście i na wyjście modelu podajemy te same \"czyste\" obrazy\n",
        "# Model uczy się wiernie rekonstruować tylko obrazy \"normalne\".\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50 # Zwiększ liczbę epok (np. do 100-200) w przypadku małego zbioru danych\n",
        "\n",
        "print(\"\\n--- Rozpoczynanie Treningu ---\")\n",
        "history = cae_model.fit(X_train, X_train,\n",
        "                        epochs=EPOCHS,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, # Mieszanie danych pomaga w generalizacji\n",
        "                        validation_data=(X_val, X_val))\n",
        "\n",
        "# Wizualizacja historii straty (Loss)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Loss Treningowy (MSE)')\n",
        "plt.plot(history.history['val_loss'], label='Loss Walidacyjny (MSE)')\n",
        "plt.title('Historia Straty Modelu')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XE7S2D_5nxvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. USTALENIE PROGU I WYKRYWANIE ANOMALII ---\n",
        "\n",
        "# 1. Obliczenie błędu rekonstrukcji dla zbioru walidacyjnego (czyste obrazy)\n",
        "reconstructions = cae_model.predict(X_val)\n",
        "# Flattening the images to calculate MSE for each image\n",
        "mse = np.mean(np.square(X_val - reconstructions), axis=(1, 2, 3))\n",
        "\n",
        "# 2. Ustalenie progu (Threshold)\n",
        "# Standardowo: średni błąd + N razy odchylenie standardowe\n",
        "# Wartość N (np. 2 lub 3) trzeba dopasować eksperymentalnie.\n",
        "MEAN_MSE = np.mean(mse)\n",
        "STD_MSE = np.std(mse)\n",
        "# Ustalenie progu anomalii - błąd wyższy niż ten jest anomalią\n",
        "ANOMALY_THRESHOLD = MEAN_MSE + 3 * STD_MSE\n",
        "\n",
        "print(f\"\\nŚredni Błąd Rekonstrukcji (MSE) w zbiorze walidacyjnym: {MEAN_MSE:.6f}\")\n",
        "print(f\"Odchylenie Standardowe Błędu (STD): {STD_MSE:.6f}\")\n",
        "print(f\"Ustalony Próg Anomalii (Threshold): {ANOMALY_THRESHOLD:.6f}\")\n",
        "\n",
        "\n",
        "# --- 5. FUNKCJA WIZUALIZACJI I TESTOWANIA ---\n",
        "\n",
        "def visualize_anomaly(image, reconstruction, threshold):\n",
        "    \"\"\"Wizualizuje obraz wejściowy, rekonstrukcję i mapę błędu (anomalie).\"\"\"\n",
        "\n",
        "    # Obliczenie mapy błędu bezwzględnego (im jaśniej, tym większy błąd/anomalia)\n",
        "    error_map = np.mean(np.abs(image - reconstruction), axis=-1)\n",
        "\n",
        "    # Normalizacja mapy błędu do zakresu [0, 1] dla wizualizacji\n",
        "    normalized_error = error_map / np.max(error_map)\n",
        "\n",
        "    # Prosty alarm na podstawie maksymalnego błędu w całym obrazie\n",
        "    overall_mse = mean_squared_error(image.flatten(), reconstruction.flatten())\n",
        "    is_anomaly = overall_mse > threshold\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Obraz wejściowy\n",
        "    axes[0].imshow(image.squeeze(), cmap='gray')\n",
        "    axes[0].set_title(f\"1. Obraz Wejściowy (Czyszczony)\")\n",
        "\n",
        "    # Obraz zrekonstruowany\n",
        "    axes[1].imshow(reconstruction.squeeze(), cmap='gray')\n",
        "    axes[1].set_title(\"2. Rekonstrukcja Modelu\")\n",
        "\n",
        "    # Mapa Błędu (Anomalii)\n",
        "    im = axes[2].imshow(error_map, cmap='hot', vmin=0, vmax=np.max(error_map))\n",
        "    axes[2].set_title(f\"3. Mapa Błędu (Alarm: {is_anomaly})\")\n",
        "    fig.colorbar(im, ax=axes[2])\n",
        "\n",
        "    # Dodanie obramowania w zależności od alarmu\n",
        "    fig.suptitle(f\"WYNIK ANALIZY: {overall_mse:.6f} (Próg: {threshold:.6f})\",\n",
        "                 color='red' if is_anomaly else 'green', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.show()\n",
        "    return is_anomaly\n",
        "\n",
        "# --- TESTOWANIE NA PRZYKŁADACH ---\n",
        "\n",
        "# TEST 1: Czysty obraz (powinien być False)\n",
        "print(\"\\n--- Test na Czystym Obrazie (z Walidacyjnego) ---\")\n",
        "idx_clean = np.random.randint(0, len(X_val))\n",
        "clean_image = X_val[idx_clean]\n",
        "clean_reconstruction = cae_model.predict(np.expand_dims(clean_image, axis=0))[0]\n",
        "visualize_anomaly(clean_image, clean_reconstruction, ANOMALY_THRESHOLD)\n",
        "\n",
        "\n",
        "# TEST 2: Obraz z dodatkiem (Anomalią)\n",
        "# Musisz wczytać obraz, na którym celowo dodałeś 'niebezpieczny przedmiot'\n",
        "# ZMIEN ŚCIEŻKĘ PONIŻEJ DO SWOJEGO OBRAZU Z ANOMALIĄ\n",
        "TEST_ANOMALY_PATH = '/content/drive/MyDrive/Twoj_Katalog_Testowy_Z_Anomalia/anomalia.bmp'\n",
        "\n",
        "# Ta sama funkcja ładowania, ale dla pojedynczego pliku\n",
        "def load_single_test_image(path, target_size, channels):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if channels == 1 else cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        return None\n",
        "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "    img = img.astype('float32') / 255.0\n",
        "    if channels == 1:\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "test_anomaly_data = load_single_test_image(TEST_ANOMALY_PATH, (IMG_WIDTH, IMG_HEIGHT), CHANNELS)\n",
        "\n",
        "if test_anomaly_data is not None:\n",
        "    print(\"\\n--- Test na Obrazie Z Anomalią ---\")\n",
        "    anomaly_image = test_anomaly_data[0]\n",
        "    anomaly_reconstruction = cae_model.predict(test_anomaly_data)[0]\n",
        "    visualize_anomaly(anomaly_image, anomaly_reconstruction, ANOMALY_THRESHOLD)\n",
        "else:\n",
        "    print(f\"\\nBŁĄD: Nie udało się wczytać testowego obrazu z anomalią z ścieżki: {TEST_ANOMALY_PATH}\")"
      ],
      "metadata": {
        "id": "oM68h1HEn12i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWEjsG5In4qf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}